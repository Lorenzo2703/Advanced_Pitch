{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_shift_midi(midi_path, midi_output, duration, song):\n",
    "    # load MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "    # get start time and instruments to keep\n",
    "    start_time, tokeep_instruments, initial_tempo = HWD_DICT[song]    \n",
    "    # compute end time\n",
    "    end_time = start_time + duration\n",
    "    # new midi object to store the cropped and modified MIDI\n",
    "\n",
    "    cropped_midi = pretty_midi.PrettyMIDI(initial_tempo=initial_tempo)\n",
    "    \n",
    "    for idx, instrument in enumerate(midi_data.instruments):\n",
    "        if idx in tokeep_instruments:\n",
    "        # new instrument in the cropped MIDI\n",
    "            new_instrument = pretty_midi.Instrument(program=instrument.program)\n",
    "            \n",
    "            for note in instrument.notes:\n",
    "                if note.start >= start_time and note.end <= end_time:\n",
    "\n",
    "                    # No more sax notes after 15 seconds in Hakuna\n",
    "                    if song == 'Hakuna' and idx == 7 and note.start > start_time+15:\n",
    "                        continue\n",
    "\n",
    "                    # Shift temporale delle note\n",
    "                    new_start = note.start - start_time\n",
    "                    new_end = note.end - start_time\n",
    "                    # Crea una nuova nota con i tempi shiftati\n",
    "                    new_note = pretty_midi.Note(\n",
    "                        pitch=note.pitch,\n",
    "                        start=new_start,\n",
    "                        end=new_end,\n",
    "                        velocity=note.velocity\n",
    "                    )\n",
    "                    new_instrument.notes.append(new_note)\n",
    "                \n",
    "            # Aggiungi lo strumento al nuovo file MIDI\n",
    "            cropped_midi.instruments.append(new_instrument)\n",
    "\n",
    "    # Salva il nuovo file MIDI\n",
    "    cropped_midi.write(midi_output)\n",
    "    return\n",
    "\n",
    "import numpy as np \n",
    "import pretty_midi\n",
    "import librosa\n",
    "from basic_pitch.constants import (\n",
    "    ANNOTATION_HOP,\n",
    "    ANNOTATIONS_BASE_FREQUENCY,\n",
    "    CONTOURS_BINS_PER_SEMITONE,\n",
    "    NOTES_BINS_PER_SEMITONE,\n",
    ")\n",
    "\n",
    "\n",
    "def create_onset(midi_path):\n",
    "\n",
    "    # Load MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "    onsets_indices = np.empty((0, 2))\n",
    "\n",
    "    # Get onsets indices\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            row = [note.start, note.pitch]\n",
    "            onsets_indices = np.vstack((onsets_indices, row))\n",
    "    # Translate from time to frame index\n",
    "    onsets_indices[:,0] = np.round(onsets_indices[:,0] / ANNOTATION_HOP)\n",
    "\n",
    "    # Translate from MIDI pitch to frequency bin\n",
    "    onsets_indices[:,1] = librosa.midi_to_hz(onsets_indices[:,1])\n",
    "    onsets_indices[:,1] = 12.0 * NOTES_BINS_PER_SEMITONE * np.log2(onsets_indices[:,1] / ANNOTATIONS_BASE_FREQUENCY)\n",
    "    onsets_indices[:,1] = onsets_indices[:,1]\n",
    "\n",
    "    # Round to the nearest integer (they are indices)\n",
    "    onsets_indices = onsets_indices.astype(int)\n",
    "    # Create onset values\n",
    "    onset_values = np.ones(onsets_indices.shape[0])\n",
    "    return onsets_indices, onset_values\n",
    "\n",
    "def create_notes(midi_path):\n",
    "\n",
    "    # Load MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "    note_indices = np.empty((0, 2))\n",
    "\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            start = np.round(note.start / ANNOTATION_HOP)\n",
    "            end = np.round(note.end / ANNOTATION_HOP)\n",
    "            # Duration in frames\n",
    "            duration = int(end - start)\n",
    "            # Translate from MIDI pitch to frequency bin\n",
    "            note_bin = librosa.midi_to_hz(note.pitch)\n",
    "            note_bin = 12.0 * NOTES_BINS_PER_SEMITONE * np.log2(note_bin / ANNOTATIONS_BASE_FREQUENCY)\n",
    "\n",
    "            for i in range(duration):\n",
    "                row = [start + i, note_bin]\n",
    "                note_indices = np.vstack((note_indices, row))\n",
    "\n",
    "    # Round to the nearest integer (they are indices)\n",
    "    note_indices = note_indices.astype(int)\n",
    "\n",
    "    # Create note values\n",
    "    note_values = np.ones(note_indices.shape[0])\n",
    "    return note_indices, note_values\n",
    "\n",
    "def create_contour(midi_path):\n",
    "    # Load MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "    note_indices = np.empty((0, 2))\n",
    "\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            start = np.round(note.start / ANNOTATION_HOP)\n",
    "            end = np.round(note.end / ANNOTATION_HOP)\n",
    "            # Duration in frames\n",
    "            duration = int(end - start)\n",
    "            # Translate from MIDI pitch to frequency bin\n",
    "            note_bin = librosa.midi_to_hz(note.pitch)\n",
    "            note_bin = 12.0 * CONTOURS_BINS_PER_SEMITONE * np.log2(note_bin / ANNOTATIONS_BASE_FREQUENCY)\n",
    "\n",
    "            for i in range(duration):\n",
    "                row = [start + i, note_bin]\n",
    "                note_indices = np.vstack((note_indices, row))\n",
    "\n",
    "    # Round to the nearest integer (they are indices)\n",
    "    note_indices = note_indices.astype(int)\n",
    "\n",
    "    # Create contour values\n",
    "    note_values = np.ones(note_indices.shape[0])\n",
    "    return note_indices, note_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 1410/6611 [01:30<07:36, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with StarWars_Whistle_122_1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1942/6611 [02:25<05:19, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with Panther_Hum_85_1940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6611/6611 [07:37<00:00, 14.46it/s]\n"
     ]
    }
   ],
   "source": [
    "#print(note_indices, note_values)\n",
    "#print(onset_indices, onset_values)\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignora il warning specifico di pretty_midi\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"pretty_midi\")\n",
    "\n",
    "\n",
    "track_ids = [] \n",
    "df = pd.read_csv(os.path.join(os.path.expanduser('~'), 'mir_datasets/hwd/MLEndHWD_Audio_Attributes.csv'))\n",
    "for i in range(len(df)):\n",
    "    track_ids.append(f'{df.loc[i,\"Song\"]}_{df.loc[i,\"Interpretation\"]}_{df.loc[i,\"Interpreter\"]}_{df.loc[i,\"Public filename\"].removesuffix(\".wav\")}')\n",
    "\n",
    "HWD_DIR = 'mir_datasets/hwd'\n",
    "for track_id in tqdm(track_ids):\n",
    "    attr_path = os.path.join(os.path.expanduser('~'),HWD_DIR,f'MLEndHWD_{track_id[:track_id.find(\"_\")]}_Audio_Files', f'{track_id[-4:]}.wav')\n",
    "    try:\n",
    "        duration = sox.file_info.duration(attr_path)\n",
    "    except:\n",
    "        print(f'Error with {track_id}')\n",
    "        continue\n",
    "    time_scale = np.arange(0, duration + ANNOTATION_HOP, ANNOTATION_HOP)\n",
    "    n_time_frames = len(time_scale)\n",
    "\n",
    "    crop_and_shift_midi(f'/home/seraf/mir_datasets/hwd/MIDI/{track_id[:track_id.find(\"_\")]}.mid', f'/home/seraf/{track_id[:track_id.find(\"_\")]}.mid', duration=duration, song=f'{track_id[:track_id.find(\"_\")]}')\n",
    "\n",
    "    note_indices, note_values = create_notes(f'/home/seraf/{track_id[:track_id.find(\"_\")]}.mid')\n",
    "    onset_indices, onset_values = create_onset(f'/home/seraf/{track_id[:track_id.find(\"_\")]}.mid')\n",
    "    contour_indices, contour_values = create_contour(f'/home/seraf/{track_id[:track_id.find(\"_\")]}.mid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error with StarWars_Whistle_122_1408\n",
    "#Error with Panther_Hum_85_1940\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWDFilterInvalidTracks(beam.DoFn):\n",
    "    DOWNLOAD_ATTRIBUTES = [\"audio_path\", \"midi_path\"]\n",
    "\n",
    "    def __init__(self, source: str):\n",
    "        self.source = source\n",
    "\n",
    "    def setup(self):\n",
    "        import apache_beam as beam\n",
    "\n",
    "        self.filesystem = beam.io.filesystems.FileSystems()\n",
    "\n",
    "    def process(self, element: Tuple[str, str]):\n",
    "        import tempfile\n",
    "\n",
    "        import apache_beam as beam\n",
    "        import sox\n",
    "        import soundfile as sf\n",
    "\n",
    "        from basic_pitch.constants import (\n",
    "            AUDIO_N_CHANNELS,\n",
    "            AUDIO_SAMPLE_RATE,\n",
    "        )\n",
    "\n",
    "        track_id, split = element\n",
    "        if split == \"omitted\":\n",
    "            return None\n",
    "        print(f\"Processing (track_id, split): ({track_id}, {split})\")\n",
    "        logging.info(f\"Processing (track_id, split): ({track_id}, {split})\")\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as local_tmp_dir:\n",
    "\n",
    "            for attr in self.DOWNLOAD_ATTRIBUTES:\n",
    "                if attr == \"audio_path\":\n",
    "                    attr_path = os.path.join(HWD_DIR,f'MLEndHWD_{track_id[:track_id.find(\"_\")]}_Audio_Files', f'{track_id[-4:]}.wav')\n",
    "                    audio_path = attr_path\n",
    "                if attr == \"midi_path\":\n",
    "                    attr_path = os.path.join(HWD_DIR, 'MIDI', f'{track_id[:track_id.find(\"_\")]}.mid')\n",
    "                source = os.path.join(self.source, attr_path)\n",
    "                dest = os.path.join(local_tmp_dir, attr_path)\n",
    "\n",
    "                if not dest:\n",
    "                    print(f\"\\n\\n\\n\\nCould not find {attr} for {track_id}\\n\\n\\n\\n\")\n",
    "                    return None\n",
    "                logging.info(f\"Downloading {attr} from {source} to {dest}\")\n",
    "                os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "                with self.filesystem.open(source) as s, open(dest, \"wb\") as d:\n",
    "                    d.write(s.read())\n",
    "\n",
    "            local_wav_path = \"{}_tmp.wav\".format(os.path.join(local_tmp_dir, audio_path))\n",
    "            tfm = sox.Transformer()\n",
    "            tfm.rate(AUDIO_SAMPLE_RATE)\n",
    "            tfm.channels(AUDIO_N_CHANNELS)\n",
    "            try:\n",
    "                tfm.build(os.path.join(local_tmp_dir, audio_path), local_wav_path)\n",
    "            except Exception as e:\n",
    "                logging.info(f\"Could not process {local_wav_path}. Exception: {e}\")\n",
    "                print(f\"\\n\\n\\n\\nCould not process {local_wav_path}. Exception: {e}\\n\\n\\n\\n\")\n",
    "                return None\n",
    "            \n",
    "            try:\n",
    "                data, samplerate = sf.read(local_wav_path)    \n",
    "                sf.write(local_wav_path, data, samplerate, subtype='PCM_16')\n",
    "            except Exception as e:\n",
    "                logging.info(f\"Could not convert to PCM {local_wav_path}. Exception: {e}\")\n",
    "                print(f\"\\n\\n\\n\\nCould not convert to PCM {local_wav_path}. Exception: {e}\\n\\n\\n\\n\")\n",
    "                return None\n",
    "            \n",
    "            ##If return None skip the track else return the track_id and split\n",
    "            yield beam.pvalue.TaggedOutput(split, track_id)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
